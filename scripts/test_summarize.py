"""æ¸¬è©¦ Ollama + Qwen2.5 æœ¬åœ°æ‘˜è¦

ç”¨æ³•: python scripts/test_summarize.py
"""

import ollama
from pathlib import Path

# å°ˆæ¡ˆæ ¹ç›®éŒ„
PROJECT_ROOT = Path(__file__).parent.parent


def test_ollama_summarize():
    """ä½¿ç”¨ Ollama + Qwen2.5 æ¸¬è©¦æœ¬åœ°æ‘˜è¦"""
    
    # è®€å–é€å­—ç¨¿
    transcript_path = PROJECT_ROOT / "temp_videos" / "transcript.txt"
    
    if not transcript_path.exists():
        print("âŒ é€å­—ç¨¿æª”æ¡ˆä¸å­˜åœ¨")
        print("   è«‹å…ˆåŸ·è¡Œ test_local_transcribe.py")
        return
    
    with open(transcript_path, "r", encoding="utf-8") as f:
        transcript = f.read()
    
    print(f"ğŸ“ é€å­—ç¨¿é•·åº¦: {len(transcript)} å­—")
    print("-" * 50)
    
    # æ‘˜è¦ prompt
    system_prompt = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å…§å®¹æ‘˜è¦åŠ©æ‰‹ã€‚ä½ çš„ä»»å‹™æ˜¯å°‡å½±ç‰‡é€å­—ç¨¿æ•´ç†æˆæ¸…æ™°ã€æœ‰æ¢ç†çš„æ‘˜è¦ã€‚

è«‹éµå¾ªä»¥ä¸‹è¦å‰‡ï¼š
1. æ‘˜è¦æ‡‰ä»¥ç¹é«”ä¸­æ–‡æ’°å¯«
2. æ‘˜è¦æ‡‰ç°¡æ½”æ˜ç­ï¼Œç´„ 100-200 å­—
3. æ¢åˆ—é‡é»æ‡‰æå– 3-5 å€‹æœ€é‡è¦çš„è¦é»
4. ä¿æŒå®¢è§€ï¼Œä¸è¦åŠ å…¥å€‹äººæ„è¦‹"""

    user_prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹å½±ç‰‡é€å­—ç¨¿ï¼Œç”Ÿæˆæ‘˜è¦å’Œæ¢åˆ—é‡é»ã€‚

é€å­—ç¨¿å…§å®¹ï¼š
{transcript}

è«‹ä»¥ä»¥ä¸‹æ ¼å¼å›è¦†ï¼š

ã€æ‘˜è¦ã€‘
ï¼ˆä¸€æ®µè©±çš„æ‘˜è¦ï¼‰

ã€é‡é»ã€‘
â€¢ é‡é»ä¸€
â€¢ é‡é»äºŒ
â€¢ é‡é»ä¸‰
ï¼ˆè¦–å…§å®¹è€Œå®šï¼Œ3-5 é»ï¼‰"""

    print("ğŸ¤– æ­£åœ¨ä½¿ç”¨ Qwen2.5 ç”Ÿæˆæ‘˜è¦...")
    print("-" * 50)
    
    try:
        response = ollama.chat(
            model="qwen2.5:7b",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            options={
                "temperature": 0.7,
                "num_predict": 1024,
            }
        )
        
        content = response["message"]["content"]
        
        print("âœ… æ‘˜è¦ç”ŸæˆæˆåŠŸï¼")
        print("-" * 50)
        print(content)
        print("-" * 50)
        
        # å„²å­˜æ‘˜è¦
        summary_path = PROJECT_ROOT / "temp_videos" / "summary.txt"
        with open(summary_path, "w", encoding="utf-8") as f:
            f.write(content)
        print(f"ğŸ’¾ æ‘˜è¦å·²å„²å­˜: {summary_path}")
        
    except ollama.ResponseError as e:
        if "model" in str(e).lower() and "not found" in str(e).lower():
            print("âŒ æ¨¡å‹æœªå®‰è£")
            print("   è«‹åŸ·è¡Œ: ollama pull qwen2.5:7b")
        else:
            print(f"âŒ éŒ¯èª¤: {e}")
    except Exception as e:
        if "connection" in str(e).lower():
            print("âŒ Ollama æœå‹™æœªå•Ÿå‹•")
            print("   è«‹å…ˆå•Ÿå‹• Ollama æ‡‰ç”¨ç¨‹å¼")
        else:
            print(f"âŒ éŒ¯èª¤: {e}")


if __name__ == "__main__":
    test_ollama_summarize()
